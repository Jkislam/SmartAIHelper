from flask import Flask, request, jsonify
import openai
import pytesseract
from PIL import Image
import base64
import io
import os
import fitz  # PyMuPDF
import json
import requests
from config import API_KEY
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs

openai.api_key = API_KEY
app = Flask(__name__)

# ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶°
with open("pdf_links.json", "r", encoding="utf-8") as f:
    pdf_links = json.load(f)

# üîπ ‡¶π‡ßã‡¶Æ ‡¶∞‡ßÅ‡¶ü
@app.route('/')
def home():
    return "<h3>‚úÖ Smart AI Helper API is Live.<br>Use POST to /summary, /mcq, /image-to-notes, /image-to-mcq, /image-to-cq, /routine, /chapter-to-mcq, /chapter-to-cq, /image-to-answer, /text-to-word-meaning, /text-to-answer</h3>"

# üîπ ‡ßß. ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‚û°Ô∏è ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶∞‡¶ø
@app.route('/summary', methods=['POST'])
def summarize():
    data = request.json
    text = data.get("text", "")
    video_url = data.get("video_url", "")

    if video_url:
        try:
            parsed_url = urlparse(video_url)
            video_id = parse_qs(parsed_url.query).get("v")
            if video_id:
                video_id = video_id[0]
                transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['bn', 'en'])
                text = " ".join([entry['text'] for entry in transcript])
            else:
                return jsonify({"error": "Invalid YouTube URL"}), 400
        except Exception as e:
            return jsonify({"error": str(e)}), 400

    if not text:
        return jsonify({"error": "No text or video transcript provided."}), 400

    prompt = f"‡¶è‡¶á ‡¶¨‡¶ï‡ßç‡¶§‡¶¨‡ßç‡¶Ø‡¶ü‡¶æ ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™‡ßá ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶¨‡ßÅ‡¶ù‡¶ø‡ßü‡ßá ‡¶¶‡¶æ‡¶ì:\n{text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"summary": response['choices'][0]['message']['content']})

# üîπ ‡ß®. ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü ‚û°Ô∏è MCQ
@app.route('/mcq', methods=['POST'])
def mcq():
    data = request.json
    chapter = data.get("chapter", "")
    prompt = f"{chapter} ‡¶¨‡¶ø‡¶∑‡ßü ‡¶•‡ßá‡¶ï‡ßá ‡ß´‡¶ü‡¶ø MCQ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶Ö‡¶™‡¶∂‡¶®‡¶∏‡¶π ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶æ‡¶ì‡•§"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"mcqs": response['choices'][0]['message']['content']})

# üîπ ‡ß©. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è ‡¶®‡ßã‡¶ü
@app.route('/image-to-notes', methods=['POST'])
def image_to_notes():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶è‡¶á ‡¶≤‡ßá‡¶ñ‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶®‡ßã‡¶ü ‡¶¨‡¶æ‡¶®‡¶æ‡¶ì:\n{extracted_text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "summary": response['choices'][0]['message']['content']
    })

# üîπ ‡ß™. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è MCQ
@app.route('/image-to-mcq', methods=['POST'])
def image_to_mcq():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶è‡¶á ‡¶≤‡ßá‡¶ñ‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡ß´‡¶ü‡¶ø MCQ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶Ö‡¶™‡¶∂‡¶®‡¶∏‡¶π ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶∏‡¶π:\n{extracted_text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "mcqs": response['choices'][0]['message']['content']
    })

# üîπ ‡ß´. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è CQ
@app.route('/image-to-cq', methods=['POST'])
def image_to_cq():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶è‡¶á ‡¶≤‡ßá‡¶ñ‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ö‡ßç‡¶õ‡ßá‡¶¶, ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶è‡¶¨‡¶Ç ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶∏‡¶π:\n{extracted_text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "cq": response['choices'][0]['message']['content']
    })

# üîπ ‡ß¨. ‡¶∞‡ßÅ‡¶ü‡¶ø‡¶® ‡¶™‡ßç‡¶≤‡ßç‡¶Ø‡¶æ‡¶®‡¶æ‡¶∞
@app.route('/routine', methods=['POST'])
def routine():
    data = request.json
    subjects = data.get("subjects", "")
    hours = data.get("hours", 2)
    prompt = f"‡¶è‡¶á ‡¶¨‡¶ø‡¶∑‡ßü‡¶ó‡ßÅ‡¶≤‡ßã: {subjects} ‡¶¶‡¶ø‡ßü‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¶‡¶ø‡¶® {hours} ‡¶ò‡¶®‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßá ‡ßß ‡¶∏‡¶™‡ßç‡¶§‡¶æ‡¶π‡ßá‡¶∞ ‡¶™‡ßú‡¶æ‡¶∂‡ßã‡¶®‡¶æ‡¶∞ ‡¶∞‡ßÅ‡¶ü‡¶ø‡¶® ‡¶¨‡¶æ‡¶®‡¶æ‡¶ì‡•§"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"routine": response['choices'][0]['message']['content']})

# üîπ ‡ß≠. ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü ‚û°Ô∏è MCQ (PDF ‡¶•‡ßá‡¶ï‡ßá)
@app.route('/chapter-to-mcq', methods=['POST'])
def chapter_to_mcq():
    data = request.json
    class_name = data.get("class")
    subject = data.get("subject")
    chapter = data.get("chapter")

    if not (class_name and subject and chapter):
        return jsonify({"error": "class, subject and chapter required"}), 400

    try:
        pdf_url = pdf_links[class_name][subject]
        response = requests.get(pdf_url)
        pdf_bytes = response.content
        text = ""
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for page in doc:
                text += page.get_text()

        prompt = f"‡¶è‡¶á ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ: '{chapter}'‡•§ ‡¶®‡¶ø‡¶ö‡ßá ‡¶¨‡¶á‡ßü‡ßá‡¶∞ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶Ü‡¶õ‡ßá‡•§ ‡¶è‡¶á ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü‡ßá‡¶∞ ‡¶Ö‡¶Ç‡¶∂ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶®‡¶ø‡ßü‡ßá ‡ß´‡¶ü‡¶ø MCQ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶Ö‡¶™‡¶∂‡¶®‡¶∏‡¶π ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶æ‡¶ì:\n\n{text[:4000]}"

        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return jsonify({"mcqs": response['choices'][0]['message']['content']})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# üîπ ‡ßÆ. ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü ‚û°Ô∏è CQ (PDF ‡¶•‡ßá‡¶ï‡ßá)
@app.route('/chapter-to-cq', methods=['POST'])
def chapter_to_cq():
    data = request.json
    class_name = data.get("class")
    subject = data.get("subject")
    chapter = data.get("chapter")

    if not (class_name and subject and chapter):
        return jsonify({"error": "class, subject and chapter required"}), 400

    try:
        pdf_url = pdf_links[class_name][subject]
        response = requests.get(pdf_url)
        pdf_bytes = response.content
        text = ""
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for page in doc:
                text += page.get_text()

        prompt = f"‡¶è‡¶á ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ: '{chapter}'‡•§ ‡¶®‡¶ø‡¶ö‡ßá ‡¶¨‡¶á‡ßü‡ßá‡¶∞ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶Ü‡¶õ‡ßá‡•§ ‡¶è‡¶á ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü‡ßá‡¶∞ ‡¶Ö‡¶Ç‡¶∂ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶®‡¶ø‡ßü‡ßá ‡ß®‡¶ü‡¶ø ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® (CQ) ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞‡¶∏‡¶π ‡¶ß‡¶æ‡¶™ ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶∏‡¶π:\n\n{text[:4000]}"

        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return jsonify({"cqs": response['choices'][0]['message']['content']})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# üîπ ‡ßØ. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è ‡¶â‡¶§‡ßç‡¶§‡¶∞ (‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®)
@app.route('/image-to-answer', methods=['POST'])
def image_to_answer():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {extracted_text}\n‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§‡¶≠‡¶æ‡¶¨‡ßá ‡¶¶‡¶æ‡¶ì‡•§"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "answer": response['choices'][0]['message']['content']
    })

# üîπ ‡ßß‡ß¶. ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‚û°Ô∏è ‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶•
@app.route('/text-to-word-meaning', methods=['POST'])
def text_to_word_meaning():
    data = request.json
    text = data.get("text", "")

    prompt = f"‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶≤‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶Ö‡¶∞‡ßç‡¶• ‡¶ì ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ó ‡¶¶‡¶æ‡¶ì:\n{text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"word_meanings": response['choices'][0]['message']['content']})

# üîπ ‡ßß‡ßß. ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‚û°Ô∏è ‡¶â‡¶§‡ßç‡¶§‡¶∞
@app.route('/text-to-answer', methods=['POST'])
def text_to_answer():
    data = request.json
    question = data.get("question", "")

    prompt = f"‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {question}\n‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§‡¶≠‡¶æ‡¶¨‡ßá ‡¶¶‡¶æ‡¶ì‡•§"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"answer": response['choices'][0]['message']['content']})

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 7860))
    app.run(host='0.0.0.0', port=port)
