from flask import Flask, request, jsonify
import openai
import pytesseract
from PIL import Image
import base64
import io
import os
from config import API_KEY
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs

openai.api_key = API_KEY
app = Flask(__name__)

# üîπ ‡¶π‡ßã‡¶Æ ‡¶∞‡ßÅ‡¶ü
@app.route('/')
def home():
    return "<h3>‚úÖ Smart AI Helper API is Live.<br>Use POST to /summary, /mcq, /image-to-notes, /image-to-mcq, /image-to-cq or /routine</h3>"

# üîπ ‡ßß. ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‚û°Ô∏è ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶∞‡¶ø
@app.route('/summary', methods=['POST'])
def summarize():
    data = request.json
    text = data.get("text", "")
    video_url = data.get("video_url", "")

    if video_url:
        try:
            parsed_url = urlparse(video_url)
            video_id = parse_qs(parsed_url.query).get("v")
            if video_id:
                video_id = video_id[0]
                transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['bn', 'en'])
                text = " ".join([entry['text'] for entry in transcript])
            else:
                return jsonify({"error": "Invalid YouTube URL"}), 400
        except Exception as e:
            return jsonify({"error": str(e)}), 400

    if not text:
        return jsonify({"error": "No text or video transcript provided."}), 400

    prompt = f"‡¶è‡¶á ‡¶¨‡¶ï‡ßç‡¶§‡¶¨‡ßç‡¶Ø‡¶ü‡¶æ ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™‡ßá ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶¨‡ßÅ‡¶ù‡¶ø‡ßü‡ßá ‡¶¶‡¶æ‡¶ì:\n{text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"summary": response['choices'][0]['message']['content']})

# üîπ ‡ß®. ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡ßü ‚û°Ô∏è MCQ
@app.route('/mcq', methods=['POST'])
def mcq():
    data = request.json
    chapter = data.get("chapter", "")
    prompt = f"{chapter} ‡¶¨‡¶ø‡¶∑‡ßü ‡¶•‡ßá‡¶ï‡ßá ‡ß´‡¶ü‡¶ø MCQ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶Ö‡¶™‡¶∂‡¶®‡¶∏‡¶π ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶æ‡¶ì‡•§"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"mcqs": response['choices'][0]['message']['content']})

# üîπ ‡ß©. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è ‡¶®‡ßã‡¶ü
@app.route('/image-to-notes', methods=['POST'])
def image_to_notes():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶è‡¶á ‡¶≤‡ßá‡¶ñ‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶®‡ßã‡¶ü ‡¶¨‡¶æ‡¶®‡¶æ‡¶ì:\n{extracted_text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "summary": response['choices'][0]['message']['content']
    })

# üîπ ‡ß™. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è MCQ
@app.route('/image-to-mcq', methods=['POST'])
def image_to_mcq():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶è‡¶á ‡¶≤‡ßá‡¶ñ‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡ß´‡¶ü‡¶ø MCQ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶Ö‡¶™‡¶∂‡¶®‡¶∏‡¶π ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶∏‡¶π:\n{extracted_text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "mcqs": response['choices'][0]['message']['content']
    })

# üîπ ‡ß´. ‡¶õ‡¶¨‡¶ø ‚û°Ô∏è CQ
@app.route('/image-to-cq', methods=['POST'])
def image_to_cq():
    data = request.json
    image_data = data.get("image_base64", "")
    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
    extracted_text = pytesseract.image_to_string(image, lang="eng+ben")

    prompt = f"‡¶è‡¶á ‡¶≤‡ßá‡¶ñ‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ö‡ßç‡¶õ‡ßá‡¶¶, ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶è‡¶¨‡¶Ç ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶∏‡¶π:\n{extracted_text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({
        "extracted_text": extracted_text,
        "cq": response['choices'][0]['message']['content']
    })

# üîπ ‡ß¨. ‡¶∞‡ßÅ‡¶ü‡¶ø‡¶® ‡¶™‡ßç‡¶≤‡ßç‡¶Ø‡¶æ‡¶®‡¶æ‡¶∞
@app.route('/routine', methods=['POST'])
def routine():
    data = request.json
    subjects = data.get("subjects", "")
    hours = data.get("hours", 2)
    prompt = f"‡¶è‡¶á ‡¶¨‡¶ø‡¶∑‡ßü‡¶ó‡ßÅ‡¶≤‡ßã: {subjects} ‡¶¶‡¶ø‡ßü‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¶‡¶ø‡¶® {hours} ‡¶ò‡¶®‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßá ‡ßß ‡¶∏‡¶™‡ßç‡¶§‡¶æ‡¶π‡ßá‡¶∞ ‡¶™‡ßú‡¶æ‡¶∂‡ßã‡¶®‡¶æ‡¶∞ ‡¶∞‡ßÅ‡¶ü‡¶ø‡¶® ‡¶¨‡¶æ‡¶®‡¶æ‡¶ì‡•§"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return jsonify({"routine": response['choices'][0]['message']['content']})

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 7860))
    app.run(host='0.0.0.0', port=port)
